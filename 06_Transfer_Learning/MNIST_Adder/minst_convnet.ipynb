{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写数字识别卷积神经网络\n",
    "\n",
    "本文件是为了配合“迁移学习”内容而编写的文件，它的作用是将训练手写识别卷积神经网络，并将其保存在硬盘上以便迁移学习的时候能够读取该文件\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第IV课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入所需要的包，请保证torchvision已经在你的环境中安装好\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyper Parameters \n",
    "image_size = 28  #图像的总尺寸28*28\n",
    "num_classes = 10  #标签的种类数\n",
    "num_epochs = 20  #训练的总循环周期\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 加载MINIST数据，如果没有下载过，就会在当前路径下新建/data子目录，并把文件存放其中\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data',  #文件存放路径\n",
    "                            train=True,   #提取训练集\n",
    "                            transform=transforms.ToTensor(),  #将图像转化为Tensor\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# 训练数据集的加载器，自动将数据分割成batch，顺序随机打乱\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "# 测试数据集的加载器，自动将数据分割成batch\n",
    "permutes = np.random.permutation(range(len(test_dataset)))\n",
    "indices_val = permutes[:5000]\n",
    "indices_test = permutes[5000:]\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset =train_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = False,\n",
    "                                                sampler = sampler_val\n",
    "                                               )\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          sampler = sampler_test\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义卷积神经网络：4和8为人为指定的两个卷积层的厚度\n",
    "depth = [4, 8]\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 5, padding = 2) #输入通道为1，输出通道为4，窗口大小为5，padding为2\n",
    "        self.pool = nn.MaxPool2d(2, 2) #一个窗口为2*2的pooling运算\n",
    "        self.conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2) #第二层卷积，输入通道为depth[0], 输出通道为depth[1]，窗口wei15，padding为2\n",
    "        self.fc1 = nn.Linear(image_size // 4 * image_size // 4 * depth[1] , 512) #一个线性连接层，输入尺寸为最后一层立方体的平铺，输出层512个节点\n",
    "        self.fc2 = nn.Linear(512, num_classes) #最后一层线性分类单元，输入为\n",
    "\n",
    "    def forward(self, x):\n",
    "        #神经网络完成一步前馈运算的过程，从输入到输出\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        # 将立体的Tensor全部转换成一维的Tensor。两次pooling操作，所以图像维度减少了1/4\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        x = F.relu(self.fc1(x)) #全链接，激活函数\n",
    "        x = F.dropout(x, training=self.training) #以默认为0.5的概率对这一层进行dropout操作\n",
    "        x = self.fc2(x) #全链接，激活函数\n",
    "        x = F.log_softmax(x, dim = 1) #log_softmax可以理解为概率对数值\n",
    "        return x\n",
    "    \n",
    "    def retrieve_features(self, x):\n",
    "        #提取卷积神经网络的特征图的函数，返回feature_map1, feature_map2为前两层卷积层的特征图\n",
    "        feature_map1 = F.relu(self.conv1(x))\n",
    "        x = self.pool(feature_map1)\n",
    "        feature_map2 = F.relu(self.conv2(x))\n",
    "        return (feature_map1, feature_map2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练周期: 0 [0/60000 (0%)]\tLoss: 2.310695\t训练正确率: 12.50%\t校验正确率: 11.06%\n",
      "训练周期: 0 [800/60000 (11%)]\tLoss: 2.293825\t训练正确率: 13.57%\t校验正确率: 27.92%\n",
      "训练周期: 0 [1600/60000 (21%)]\tLoss: 2.263970\t训练正确率: 17.09%\t校验正确率: 31.66%\n",
      "训练周期: 0 [2400/60000 (32%)]\tLoss: 2.207286\t训练正确率: 19.95%\t校验正确率: 36.80%\n",
      "训练周期: 0 [3200/60000 (43%)]\tLoss: 1.783102\t训练正确率: 25.33%\t校验正确率: 65.08%\n",
      "训练周期: 0 [4000/60000 (53%)]\tLoss: 1.104822\t训练正确率: 32.82%\t校验正确率: 78.40%\n",
      "训练周期: 0 [4800/60000 (64%)]\tLoss: 0.817422\t训练正确率: 39.96%\t校验正确率: 84.12%\n",
      "训练周期: 0 [5600/60000 (75%)]\tLoss: 0.534223\t训练正确率: 45.91%\t校验正确率: 87.72%\n",
      "训练周期: 0 [6400/60000 (85%)]\tLoss: 0.562122\t训练正确率: 50.73%\t校验正确率: 88.82%\n",
      "训练周期: 0 [7200/60000 (96%)]\tLoss: 0.641377\t训练正确率: 54.61%\t校验正确率: 89.64%\n",
      "训练周期: 1 [0/60000 (0%)]\tLoss: 0.380129\t训练正确率: 87.50%\t校验正确率: 90.00%\n",
      "训练周期: 1 [800/60000 (11%)]\tLoss: 0.379836\t训练正确率: 87.10%\t校验正确率: 90.30%\n",
      "训练周期: 1 [1600/60000 (21%)]\tLoss: 0.325265\t训练正确率: 87.77%\t校验正确率: 91.40%\n",
      "训练周期: 1 [2400/60000 (32%)]\tLoss: 0.453496\t训练正确率: 88.30%\t校验正确率: 91.26%\n",
      "训练周期: 1 [3200/60000 (43%)]\tLoss: 0.382892\t训练正确率: 88.59%\t校验正确率: 91.30%\n",
      "训练周期: 1 [4000/60000 (53%)]\tLoss: 0.375090\t训练正确率: 88.88%\t校验正确率: 92.52%\n",
      "训练周期: 1 [4800/60000 (64%)]\tLoss: 0.320430\t训练正确率: 89.16%\t校验正确率: 92.54%\n",
      "训练周期: 1 [5600/60000 (75%)]\tLoss: 0.227632\t训练正确率: 89.46%\t校验正确率: 92.34%\n",
      "训练周期: 1 [6400/60000 (85%)]\tLoss: 0.176045\t训练正确率: 89.73%\t校验正确率: 92.84%\n",
      "训练周期: 1 [7200/60000 (96%)]\tLoss: 0.222001\t训练正确率: 89.89%\t校验正确率: 93.68%\n",
      "训练周期: 2 [0/60000 (0%)]\tLoss: 0.335797\t训练正确率: 93.75%\t校验正确率: 93.78%\n",
      "训练周期: 2 [800/60000 (11%)]\tLoss: 0.298611\t训练正确率: 91.38%\t校验正确率: 93.86%\n",
      "训练周期: 2 [1600/60000 (21%)]\tLoss: 0.162824\t训练正确率: 91.85%\t校验正确率: 93.96%\n",
      "训练周期: 2 [2400/60000 (32%)]\tLoss: 0.181203\t训练正确率: 91.92%\t校验正确率: 93.70%\n",
      "训练周期: 2 [3200/60000 (43%)]\tLoss: 0.224682\t训练正确率: 92.20%\t校验正确率: 94.26%\n",
      "训练周期: 2 [4000/60000 (53%)]\tLoss: 0.258178\t训练正确率: 92.39%\t校验正确率: 94.52%\n",
      "训练周期: 2 [4800/60000 (64%)]\tLoss: 0.192443\t训练正确率: 92.48%\t校验正确率: 94.76%\n",
      "训练周期: 2 [5600/60000 (75%)]\tLoss: 0.151261\t训练正确率: 92.62%\t校验正确率: 94.88%\n",
      "训练周期: 2 [6400/60000 (85%)]\tLoss: 0.237406\t训练正确率: 92.70%\t校验正确率: 94.36%\n",
      "训练周期: 2 [7200/60000 (96%)]\tLoss: 0.140384\t训练正确率: 92.87%\t校验正确率: 95.04%\n",
      "训练周期: 3 [0/60000 (0%)]\tLoss: 0.148180\t训练正确率: 95.31%\t校验正确率: 95.28%\n",
      "训练周期: 3 [800/60000 (11%)]\tLoss: 0.096728\t训练正确率: 93.41%\t校验正确率: 95.18%\n",
      "训练周期: 3 [1600/60000 (21%)]\tLoss: 0.144808\t训练正确率: 93.69%\t校验正确率: 95.54%\n",
      "训练周期: 3 [2400/60000 (32%)]\tLoss: 0.105194\t训练正确率: 93.84%\t校验正确率: 95.18%\n",
      "训练周期: 3 [3200/60000 (43%)]\tLoss: 0.118769\t训练正确率: 93.85%\t校验正确率: 95.70%\n",
      "训练周期: 3 [4000/60000 (53%)]\tLoss: 0.163106\t训练正确率: 93.92%\t校验正确率: 95.40%\n",
      "训练周期: 3 [4800/60000 (64%)]\tLoss: 0.293718\t训练正确率: 93.95%\t校验正确率: 95.50%\n",
      "训练周期: 3 [5600/60000 (75%)]\tLoss: 0.149651\t训练正确率: 94.09%\t校验正确率: 95.88%\n",
      "训练周期: 3 [6400/60000 (85%)]\tLoss: 0.123116\t训练正确率: 94.17%\t校验正确率: 95.82%\n",
      "训练周期: 3 [7200/60000 (96%)]\tLoss: 0.275720\t训练正确率: 94.21%\t校验正确率: 95.96%\n",
      "训练周期: 4 [0/60000 (0%)]\tLoss: 0.106494\t训练正确率: 96.88%\t校验正确率: 95.74%\n",
      "训练周期: 4 [800/60000 (11%)]\tLoss: 0.051335\t训练正确率: 95.44%\t校验正确率: 96.04%\n",
      "训练周期: 4 [1600/60000 (21%)]\tLoss: 0.326608\t训练正确率: 94.99%\t校验正确率: 95.98%\n",
      "训练周期: 4 [2400/60000 (32%)]\tLoss: 0.160472\t训练正确率: 94.90%\t校验正确率: 96.00%\n",
      "训练周期: 4 [3200/60000 (43%)]\tLoss: 0.177291\t训练正确率: 94.88%\t校验正确率: 96.14%\n",
      "训练周期: 4 [4000/60000 (53%)]\tLoss: 0.144788\t训练正确率: 94.96%\t校验正确率: 96.00%\n",
      "训练周期: 4 [4800/60000 (64%)]\tLoss: 0.142092\t训练正确率: 95.00%\t校验正确率: 96.32%\n",
      "训练周期: 4 [5600/60000 (75%)]\tLoss: 0.129132\t训练正确率: 95.08%\t校验正确率: 96.40%\n",
      "训练周期: 4 [6400/60000 (85%)]\tLoss: 0.180097\t训练正确率: 95.11%\t校验正确率: 96.38%\n",
      "训练周期: 4 [7200/60000 (96%)]\tLoss: 0.096298\t训练正确率: 95.20%\t校验正确率: 96.26%\n",
      "训练周期: 5 [0/60000 (0%)]\tLoss: 0.115579\t训练正确率: 95.31%\t校验正确率: 96.18%\n",
      "训练周期: 5 [800/60000 (11%)]\tLoss: 0.253499\t训练正确率: 95.42%\t校验正确率: 96.56%\n",
      "训练周期: 5 [1600/60000 (21%)]\tLoss: 0.180201\t训练正确率: 95.33%\t校验正确率: 96.52%\n",
      "训练周期: 5 [2400/60000 (32%)]\tLoss: 0.051465\t训练正确率: 95.61%\t校验正确率: 96.38%\n",
      "训练周期: 5 [3200/60000 (43%)]\tLoss: 0.118603\t训练正确率: 95.66%\t校验正确率: 96.42%\n",
      "训练周期: 5 [4000/60000 (53%)]\tLoss: 0.113998\t训练正确率: 95.62%\t校验正确率: 96.64%\n",
      "训练周期: 5 [4800/60000 (64%)]\tLoss: 0.100127\t训练正确率: 95.67%\t校验正确率: 96.44%\n",
      "训练周期: 5 [5600/60000 (75%)]\tLoss: 0.071534\t训练正确率: 95.70%\t校验正确率: 96.72%\n",
      "训练周期: 5 [6400/60000 (85%)]\tLoss: 0.235649\t训练正确率: 95.68%\t校验正确率: 96.60%\n",
      "训练周期: 5 [7200/60000 (96%)]\tLoss: 0.156777\t训练正确率: 95.67%\t校验正确率: 96.86%\n",
      "训练周期: 6 [0/60000 (0%)]\tLoss: 0.087622\t训练正确率: 96.88%\t校验正确率: 96.84%\n",
      "训练周期: 6 [800/60000 (11%)]\tLoss: 0.166938\t训练正确率: 96.04%\t校验正确率: 96.66%\n",
      "训练周期: 6 [1600/60000 (21%)]\tLoss: 0.209049\t训练正确率: 96.02%\t校验正确率: 96.78%\n",
      "训练周期: 6 [2400/60000 (32%)]\tLoss: 0.103027\t训练正确率: 96.00%\t校验正确率: 96.70%\n",
      "训练周期: 6 [3200/60000 (43%)]\tLoss: 0.145488\t训练正确率: 96.07%\t校验正确率: 96.82%\n",
      "训练周期: 6 [4000/60000 (53%)]\tLoss: 0.065650\t训练正确率: 96.14%\t校验正确率: 97.00%\n",
      "训练周期: 6 [4800/60000 (64%)]\tLoss: 0.052442\t训练正确率: 96.18%\t校验正确率: 96.96%\n",
      "训练周期: 6 [5600/60000 (75%)]\tLoss: 0.107744\t训练正确率: 96.23%\t校验正确率: 97.10%\n",
      "训练周期: 6 [6400/60000 (85%)]\tLoss: 0.082552\t训练正确率: 96.21%\t校验正确率: 96.80%\n",
      "训练周期: 6 [7200/60000 (96%)]\tLoss: 0.015517\t训练正确率: 96.20%\t校验正确率: 96.86%\n",
      "训练周期: 7 [0/60000 (0%)]\tLoss: 0.170381\t训练正确率: 95.31%\t校验正确率: 97.24%\n",
      "训练周期: 7 [800/60000 (11%)]\tLoss: 0.064856\t训练正确率: 96.75%\t校验正确率: 97.24%\n",
      "训练周期: 7 [1600/60000 (21%)]\tLoss: 0.072062\t训练正确率: 96.64%\t校验正确率: 97.20%\n",
      "训练周期: 7 [2400/60000 (32%)]\tLoss: 0.125497\t训练正确率: 96.59%\t校验正确率: 97.12%\n",
      "训练周期: 7 [3200/60000 (43%)]\tLoss: 0.157553\t训练正确率: 96.59%\t校验正确率: 97.24%\n",
      "训练周期: 7 [4000/60000 (53%)]\tLoss: 0.108797\t训练正确率: 96.60%\t校验正确率: 97.18%\n",
      "训练周期: 7 [4800/60000 (64%)]\tLoss: 0.077876\t训练正确率: 96.56%\t校验正确率: 97.36%\n",
      "训练周期: 7 [5600/60000 (75%)]\tLoss: 0.037273\t训练正确率: 96.51%\t校验正确率: 97.24%\n",
      "训练周期: 7 [6400/60000 (85%)]\tLoss: 0.065531\t训练正确率: 96.54%\t校验正确率: 97.24%\n",
      "训练周期: 7 [7200/60000 (96%)]\tLoss: 0.134651\t训练正确率: 96.52%\t校验正确率: 97.18%\n",
      "训练周期: 8 [0/60000 (0%)]\tLoss: 0.092592\t训练正确率: 95.31%\t校验正确率: 97.36%\n",
      "训练周期: 8 [800/60000 (11%)]\tLoss: 0.095342\t训练正确率: 96.43%\t校验正确率: 97.04%\n",
      "训练周期: 8 [1600/60000 (21%)]\tLoss: 0.061677\t训练正确率: 96.49%\t校验正确率: 96.90%\n",
      "训练周期: 8 [2400/60000 (32%)]\tLoss: 0.088797\t训练正确率: 96.40%\t校验正确率: 97.48%\n",
      "训练周期: 8 [3200/60000 (43%)]\tLoss: 0.045784\t训练正确率: 96.46%\t校验正确率: 97.20%\n",
      "训练周期: 8 [4000/60000 (53%)]\tLoss: 0.156858\t训练正确率: 96.56%\t校验正确率: 97.32%\n",
      "训练周期: 8 [4800/60000 (64%)]\tLoss: 0.149669\t训练正确率: 96.58%\t校验正确率: 97.44%\n",
      "训练周期: 8 [5600/60000 (75%)]\tLoss: 0.187674\t训练正确率: 96.59%\t校验正确率: 97.38%\n",
      "训练周期: 8 [6400/60000 (85%)]\tLoss: 0.075215\t训练正确率: 96.67%\t校验正确率: 97.48%\n",
      "训练周期: 8 [7200/60000 (96%)]\tLoss: 0.023124\t训练正确率: 96.73%\t校验正确率: 97.36%\n",
      "训练周期: 9 [0/60000 (0%)]\tLoss: 0.091605\t训练正确率: 96.88%\t校验正确率: 97.42%\n",
      "训练周期: 9 [800/60000 (11%)]\tLoss: 0.041647\t训练正确率: 96.69%\t校验正确率: 97.32%\n",
      "训练周期: 9 [1600/60000 (21%)]\tLoss: 0.022906\t训练正确率: 96.70%\t校验正确率: 97.36%\n",
      "训练周期: 9 [2400/60000 (32%)]\tLoss: 0.051629\t训练正确率: 96.80%\t校验正确率: 97.44%\n",
      "训练周期: 9 [3200/60000 (43%)]\tLoss: 0.087750\t训练正确率: 96.82%\t校验正确率: 97.58%\n",
      "训练周期: 9 [4000/60000 (53%)]\tLoss: 0.085598\t训练正确率: 96.93%\t校验正确率: 97.58%\n",
      "训练周期: 9 [4800/60000 (64%)]\tLoss: 0.048746\t训练正确率: 96.99%\t校验正确率: 97.46%\n",
      "训练周期: 9 [5600/60000 (75%)]\tLoss: 0.063250\t训练正确率: 96.96%\t校验正确率: 97.68%\n",
      "训练周期: 9 [6400/60000 (85%)]\tLoss: 0.141112\t训练正确率: 96.99%\t校验正确率: 97.72%\n",
      "训练周期: 9 [7200/60000 (96%)]\tLoss: 0.073360\t训练正确率: 96.99%\t校验正确率: 97.84%\n",
      "训练周期: 10 [0/60000 (0%)]\tLoss: 0.024962\t训练正确率: 100.00%\t校验正确率: 97.68%\n",
      "训练周期: 10 [800/60000 (11%)]\tLoss: 0.326526\t训练正确率: 97.29%\t校验正确率: 97.82%\n",
      "训练周期: 10 [1600/60000 (21%)]\tLoss: 0.040254\t训练正确率: 97.18%\t校验正确率: 97.94%\n",
      "训练周期: 10 [2400/60000 (32%)]\tLoss: 0.154905\t训练正确率: 97.16%\t校验正确率: 97.72%\n",
      "训练周期: 10 [3200/60000 (43%)]\tLoss: 0.045024\t训练正确率: 97.11%\t校验正确率: 97.90%\n",
      "训练周期: 10 [4000/60000 (53%)]\tLoss: 0.072520\t训练正确率: 97.13%\t校验正确率: 97.94%\n",
      "训练周期: 10 [4800/60000 (64%)]\tLoss: 0.145856\t训练正确率: 97.14%\t校验正确率: 97.80%\n",
      "训练周期: 10 [5600/60000 (75%)]\tLoss: 0.036489\t训练正确率: 97.13%\t校验正确率: 97.84%\n",
      "训练周期: 10 [6400/60000 (85%)]\tLoss: 0.029267\t训练正确率: 97.12%\t校验正确率: 97.92%\n",
      "训练周期: 10 [7200/60000 (96%)]\tLoss: 0.129931\t训练正确率: 97.13%\t校验正确率: 97.74%\n",
      "训练周期: 11 [0/60000 (0%)]\tLoss: 0.051294\t训练正确率: 96.88%\t校验正确率: 97.88%\n",
      "训练周期: 11 [800/60000 (11%)]\tLoss: 0.068370\t训练正确率: 97.15%\t校验正确率: 97.86%\n",
      "训练周期: 11 [1600/60000 (21%)]\tLoss: 0.028809\t训练正确率: 97.29%\t校验正确率: 97.94%\n",
      "训练周期: 11 [2400/60000 (32%)]\tLoss: 0.024958\t训练正确率: 97.21%\t校验正确率: 97.86%\n",
      "训练周期: 11 [3200/60000 (43%)]\tLoss: 0.246855\t训练正确率: 97.24%\t校验正确率: 97.88%\n",
      "训练周期: 11 [4000/60000 (53%)]\tLoss: 0.057515\t训练正确率: 97.18%\t校验正确率: 97.90%\n",
      "训练周期: 11 [4800/60000 (64%)]\tLoss: 0.119411\t训练正确率: 97.21%\t校验正确率: 98.06%\n",
      "训练周期: 11 [5600/60000 (75%)]\tLoss: 0.218868\t训练正确率: 97.21%\t校验正确率: 97.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练周期: 11 [6400/60000 (85%)]\tLoss: 0.049122\t训练正确率: 97.23%\t校验正确率: 98.10%\n",
      "训练周期: 11 [7200/60000 (96%)]\tLoss: 0.031089\t训练正确率: 97.28%\t校验正确率: 98.18%\n",
      "训练周期: 12 [0/60000 (0%)]\tLoss: 0.089008\t训练正确率: 96.88%\t校验正确率: 98.04%\n",
      "训练周期: 12 [800/60000 (11%)]\tLoss: 0.061546\t训练正确率: 97.37%\t校验正确率: 98.20%\n",
      "训练周期: 12 [1600/60000 (21%)]\tLoss: 0.037016\t训练正确率: 97.37%\t校验正确率: 98.02%\n",
      "训练周期: 12 [2400/60000 (32%)]\tLoss: 0.085749\t训练正确率: 97.58%\t校验正确率: 98.00%\n",
      "训练周期: 12 [3200/60000 (43%)]\tLoss: 0.026387\t训练正确率: 97.48%\t校验正确率: 98.10%\n",
      "训练周期: 12 [4000/60000 (53%)]\tLoss: 0.203794\t训练正确率: 97.53%\t校验正确率: 98.02%\n",
      "训练周期: 12 [4800/60000 (64%)]\tLoss: 0.021496\t训练正确率: 97.55%\t校验正确率: 97.88%\n",
      "训练周期: 12 [5600/60000 (75%)]\tLoss: 0.111330\t训练正确率: 97.52%\t校验正确率: 98.00%\n",
      "训练周期: 12 [6400/60000 (85%)]\tLoss: 0.042787\t训练正确率: 97.49%\t校验正确率: 97.98%\n",
      "训练周期: 12 [7200/60000 (96%)]\tLoss: 0.023610\t训练正确率: 97.51%\t校验正确率: 98.08%\n",
      "训练周期: 13 [0/60000 (0%)]\tLoss: 0.075813\t训练正确率: 96.88%\t校验正确率: 98.14%\n",
      "训练周期: 13 [800/60000 (11%)]\tLoss: 0.116814\t训练正确率: 97.62%\t校验正确率: 98.14%\n",
      "训练周期: 13 [1600/60000 (21%)]\tLoss: 0.044336\t训练正确率: 97.57%\t校验正确率: 98.04%\n",
      "训练周期: 13 [2400/60000 (32%)]\tLoss: 0.077663\t训练正确率: 97.60%\t校验正确率: 98.22%\n",
      "训练周期: 13 [3200/60000 (43%)]\tLoss: 0.147840\t训练正确率: 97.60%\t校验正确率: 98.00%\n",
      "训练周期: 13 [4000/60000 (53%)]\tLoss: 0.060850\t训练正确率: 97.57%\t校验正确率: 98.32%\n",
      "训练周期: 13 [4800/60000 (64%)]\tLoss: 0.029715\t训练正确率: 97.58%\t校验正确率: 98.16%\n",
      "训练周期: 13 [5600/60000 (75%)]\tLoss: 0.039431\t训练正确率: 97.62%\t校验正确率: 98.28%\n",
      "训练周期: 13 [6400/60000 (85%)]\tLoss: 0.022950\t训练正确率: 97.62%\t校验正确率: 98.04%\n",
      "训练周期: 13 [7200/60000 (96%)]\tLoss: 0.076059\t训练正确率: 97.63%\t校验正确率: 98.22%\n",
      "训练周期: 14 [0/60000 (0%)]\tLoss: 0.034997\t训练正确率: 98.44%\t校验正确率: 98.16%\n",
      "训练周期: 14 [800/60000 (11%)]\tLoss: 0.040820\t训练正确率: 97.88%\t校验正确率: 98.24%\n",
      "训练周期: 14 [1600/60000 (21%)]\tLoss: 0.054039\t训练正确率: 97.78%\t校验正确率: 98.14%\n",
      "训练周期: 14 [2400/60000 (32%)]\tLoss: 0.061594\t训练正确率: 97.79%\t校验正确率: 98.30%\n",
      "训练周期: 14 [3200/60000 (43%)]\tLoss: 0.172372\t训练正确率: 97.81%\t校验正确率: 98.38%\n",
      "训练周期: 14 [4000/60000 (53%)]\tLoss: 0.019461\t训练正确率: 97.74%\t校验正确率: 98.20%\n",
      "训练周期: 14 [4800/60000 (64%)]\tLoss: 0.021941\t训练正确率: 97.70%\t校验正确率: 98.42%\n",
      "训练周期: 14 [5600/60000 (75%)]\tLoss: 0.028515\t训练正确率: 97.67%\t校验正确率: 98.36%\n",
      "训练周期: 14 [6400/60000 (85%)]\tLoss: 0.097060\t训练正确率: 97.68%\t校验正确率: 98.36%\n",
      "训练周期: 14 [7200/60000 (96%)]\tLoss: 0.106198\t训练正确率: 97.64%\t校验正确率: 98.32%\n",
      "训练周期: 15 [0/60000 (0%)]\tLoss: 0.062261\t训练正确率: 98.44%\t校验正确率: 98.30%\n",
      "训练周期: 15 [800/60000 (11%)]\tLoss: 0.034117\t训练正确率: 97.79%\t校验正确率: 98.26%\n",
      "训练周期: 15 [1600/60000 (21%)]\tLoss: 0.144068\t训练正确率: 97.78%\t校验正确率: 98.30%\n",
      "训练周期: 15 [2400/60000 (32%)]\tLoss: 0.203574\t训练正确率: 97.82%\t校验正确率: 98.42%\n",
      "训练周期: 15 [3200/60000 (43%)]\tLoss: 0.046304\t训练正确率: 97.87%\t校验正确率: 98.40%\n",
      "训练周期: 15 [4000/60000 (53%)]\tLoss: 0.011936\t训练正确率: 97.87%\t校验正确率: 98.26%\n",
      "训练周期: 15 [4800/60000 (64%)]\tLoss: 0.055743\t训练正确率: 97.80%\t校验正确率: 98.42%\n",
      "训练周期: 15 [5600/60000 (75%)]\tLoss: 0.070627\t训练正确率: 97.83%\t校验正确率: 98.56%\n",
      "训练周期: 15 [6400/60000 (85%)]\tLoss: 0.084882\t训练正确率: 97.81%\t校验正确率: 98.46%\n",
      "训练周期: 15 [7200/60000 (96%)]\tLoss: 0.039367\t训练正确率: 97.80%\t校验正确率: 98.46%\n",
      "训练周期: 16 [0/60000 (0%)]\tLoss: 0.025585\t训练正确率: 100.00%\t校验正确率: 98.36%\n",
      "训练周期: 16 [800/60000 (11%)]\tLoss: 0.296222\t训练正确率: 97.85%\t校验正确率: 98.38%\n",
      "训练周期: 16 [1600/60000 (21%)]\tLoss: 0.037022\t训练正确率: 97.83%\t校验正确率: 98.50%\n",
      "训练周期: 16 [2400/60000 (32%)]\tLoss: 0.043804\t训练正确率: 97.79%\t校验正确率: 98.52%\n",
      "训练周期: 16 [3200/60000 (43%)]\tLoss: 0.090210\t训练正确率: 97.82%\t校验正确率: 98.46%\n",
      "训练周期: 16 [4000/60000 (53%)]\tLoss: 0.029625\t训练正确率: 97.88%\t校验正确率: 98.62%\n",
      "训练周期: 16 [4800/60000 (64%)]\tLoss: 0.135731\t训练正确率: 97.93%\t校验正确率: 98.38%\n",
      "训练周期: 16 [5600/60000 (75%)]\tLoss: 0.014954\t训练正确率: 97.97%\t校验正确率: 98.38%\n",
      "训练周期: 16 [6400/60000 (85%)]\tLoss: 0.069818\t训练正确率: 97.94%\t校验正确率: 98.48%\n",
      "训练周期: 16 [7200/60000 (96%)]\tLoss: 0.018319\t训练正确率: 97.94%\t校验正确率: 98.54%\n",
      "训练周期: 17 [0/60000 (0%)]\tLoss: 0.122976\t训练正确率: 95.31%\t校验正确率: 98.36%\n",
      "训练周期: 17 [800/60000 (11%)]\tLoss: 0.022069\t训练正确率: 98.25%\t校验正确率: 98.52%\n",
      "训练周期: 17 [1600/60000 (21%)]\tLoss: 0.015973\t训练正确率: 98.10%\t校验正确率: 98.36%\n",
      "训练周期: 17 [2400/60000 (32%)]\tLoss: 0.012419\t训练正确率: 98.12%\t校验正确率: 98.54%\n",
      "训练周期: 17 [3200/60000 (43%)]\tLoss: 0.014946\t训练正确率: 98.11%\t校验正确率: 98.54%\n",
      "训练周期: 17 [4000/60000 (53%)]\tLoss: 0.081320\t训练正确率: 98.10%\t校验正确率: 98.48%\n",
      "训练周期: 17 [4800/60000 (64%)]\tLoss: 0.255572\t训练正确率: 98.04%\t校验正确率: 98.56%\n",
      "训练周期: 17 [5600/60000 (75%)]\tLoss: 0.054500\t训练正确率: 98.02%\t校验正确率: 98.46%\n",
      "训练周期: 17 [6400/60000 (85%)]\tLoss: 0.043324\t训练正确率: 98.00%\t校验正确率: 98.64%\n",
      "训练周期: 17 [7200/60000 (96%)]\tLoss: 0.063795\t训练正确率: 97.99%\t校验正确率: 98.66%\n",
      "训练周期: 18 [0/60000 (0%)]\tLoss: 0.113886\t训练正确率: 93.75%\t校验正确率: 98.58%\n",
      "训练周期: 18 [800/60000 (11%)]\tLoss: 0.008148\t训练正确率: 97.99%\t校验正确率: 98.62%\n",
      "训练周期: 18 [1600/60000 (21%)]\tLoss: 0.108961\t训练正确率: 98.12%\t校验正确率: 98.60%\n",
      "训练周期: 18 [2400/60000 (32%)]\tLoss: 0.027104\t训练正确率: 98.09%\t校验正确率: 98.52%\n",
      "训练周期: 18 [3200/60000 (43%)]\tLoss: 0.069593\t训练正确率: 98.09%\t校验正确率: 98.62%\n",
      "训练周期: 18 [4000/60000 (53%)]\tLoss: 0.086869\t训练正确率: 98.06%\t校验正确率: 98.58%\n",
      "训练周期: 18 [4800/60000 (64%)]\tLoss: 0.029663\t训练正确率: 98.06%\t校验正确率: 98.58%\n",
      "训练周期: 18 [5600/60000 (75%)]\tLoss: 0.053081\t训练正确率: 98.08%\t校验正确率: 98.56%\n",
      "训练周期: 18 [6400/60000 (85%)]\tLoss: 0.080131\t训练正确率: 98.06%\t校验正确率: 98.58%\n",
      "训练周期: 18 [7200/60000 (96%)]\tLoss: 0.074665\t训练正确率: 98.09%\t校验正确率: 98.62%\n",
      "训练周期: 19 [0/60000 (0%)]\tLoss: 0.105450\t训练正确率: 98.44%\t校验正确率: 98.60%\n",
      "训练周期: 19 [800/60000 (11%)]\tLoss: 0.023789\t训练正确率: 98.28%\t校验正确率: 98.56%\n",
      "训练周期: 19 [1600/60000 (21%)]\tLoss: 0.174978\t训练正确率: 98.37%\t校验正确率: 98.68%\n",
      "训练周期: 19 [2400/60000 (32%)]\tLoss: 0.093770\t训练正确率: 98.30%\t校验正确率: 98.54%\n",
      "训练周期: 19 [3200/60000 (43%)]\tLoss: 0.061117\t训练正确率: 98.21%\t校验正确率: 98.80%\n",
      "训练周期: 19 [4000/60000 (53%)]\tLoss: 0.029298\t训练正确率: 98.16%\t校验正确率: 98.64%\n",
      "训练周期: 19 [4800/60000 (64%)]\tLoss: 0.089262\t训练正确率: 98.20%\t校验正确率: 98.70%\n",
      "训练周期: 19 [5600/60000 (75%)]\tLoss: 0.062325\t训练正确率: 98.19%\t校验正确率: 98.60%\n",
      "训练周期: 19 [6400/60000 (85%)]\tLoss: 0.049229\t训练正确率: 98.17%\t校验正确率: 98.70%\n",
      "训练周期: 19 [7200/60000 (96%)]\tLoss: 0.012241\t训练正确率: 98.19%\t校验正确率: 98.64%\n"
     ]
    }
   ],
   "source": [
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行10列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素\n",
    "net = ConvNet() #新建一个卷积神经网络的实例\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #Loss函数的定义\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #定义优化器\n",
    "\n",
    "record = [] #记录准确率等数值的容器\n",
    "weights = [] #每若干步就记录一次卷积核\n",
    "\n",
    "#开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_rights = [] #记录训练数据集准确率的容器\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  #针对容器中的每一个批进行循环\n",
    "        data, target = data.clone().detach().requires_grad_(True), target.clone().detach() #将Tensor转化为Variable，data为图像，target为标签\n",
    "        net.train() # 给网络模型做标记，标志说模型在训练集上训练\n",
    "        output = net(data) #完成一次预测\n",
    "        loss = criterion(output, target) #计算误差\n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        loss.backward() #反向传播\n",
    "        optimizer.step() #一步随机梯度下降\n",
    "        right = rightness(output, target) #计算准确率所需数值，返回正确的数值为（正确样例数，总样本数）\n",
    "        train_rights.append(right) #将计算结果装到列表容器中\n",
    "\n",
    "    \n",
    "        if batch_idx % 100 == 0: #每间隔100个batch执行一次\n",
    "            \n",
    "            #train_r为一个二元组，分别记录训练集中分类正确的数量和该集合中总的样本数\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            \n",
    "            net.eval() # 给网络模型做标记，标志说模型在训练集上训练\n",
    "            val_rights = [] #记录校验数据集准确率的容器\n",
    "            for (data, target) in validation_loader:\n",
    "                data, target = data.clone().detach().requires_grad_(True), target.clone().detach() \n",
    "                output = net(data) #完成一次预测\n",
    "                right = rightness(output, target) #计算准确率所需数值，返回正确的数值为（正确样例数，总样本数）\n",
    "                val_rights.append(right)\n",
    "            \n",
    "            #val_r为一个二元组，分别记录校验集中分类正确的数量和该集合中总的样本数\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "            \n",
    "            #打印准确率等数值，其中正确率为本训练周期Epoch开始后到目前撮的正确率的平均值\n",
    "            print('训练周期: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t训练正确率: {:.2f}%\\t校验正确率: {:.2f}%'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data, \n",
    "                100. * train_r[0].numpy() / train_r[1], \n",
    "                100. * val_r[0].numpy() / val_r[1]))\n",
    "            \n",
    "            #将准确率和权重等数值加载到容器中，以方便后续处理\n",
    "            record.append((100 - 100. * train_r[0].numpy() / train_r[1], 100 - 100. * val_r[0].numpy() / val_r[1]))\n",
    "            weights.append([net.conv1.weight.data.clone(), net.conv1.bias.data.clone(), \n",
    "                            net.conv2.weight.data.clone(), net.conv2.bias.data.clone()])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Z:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ConvNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# 在这里保存已经训练好的神经网络\n",
    "torch.save(net, 'minst_conv_checkpoint') #后面的字符串为保存文件的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAACYCAYAAADwfX2XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#提取第一层卷积层的卷积核\n",
    "plt.figure(figsize = (10, 7))\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i + 1)\n",
    "    plt.imshow(net.conv1.weight.data.numpy()[i,0,...])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAIhCAYAAAAo4dnZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制第二层的卷积核\n",
    "plt.figure(figsize = (15, 10))\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        plt.subplot(4, 8, i * 8 + j + 1)\n",
    "        plt.imshow(net.conv2.weight.data.numpy()[j, i,...])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
