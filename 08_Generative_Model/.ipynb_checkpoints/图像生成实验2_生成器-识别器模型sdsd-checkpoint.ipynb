{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "    os.mk_dir(\"./temp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "input_dim = 100\n",
    "num_channels = 1\n",
    "num_features = 64\n",
    "batch_size = 64\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "\n",
    "train_dataset = dsets.MNIST(root = \"./data\",\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = \"./data\",\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "indices = range(len(test_dataset))\n",
    "indices_val = indices[:5000]\n",
    "indices_test = indices[5000:]\n",
    "\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                sampler = sampler_val)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          sampler = sampler_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、生成器预测图像模型\n",
    "\n",
    "在这个模型中，我们根据输入的手写数字生成一张图像，并让这个图像与数据中的样本图像尽可能一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelG, self).__init__()\n",
    "        self.model = nn.Sequential() #model为一个内嵌的序列化的神经网络模型\n",
    "        \n",
    "        # 利用add_module增加一个反卷积层，输入为input_dim维，输出为2*num_features维，窗口大小为5，padding是0\n",
    "        # 输入图像大小为1，输出图像大小为W'=(W-1)S-2P+K+P'=(1-1)*2-2*0+5+0=3, 5*5\n",
    "        self.model.add_module('deconv1',nn.ConvTranspose2d(input_dim, num_features*2, 5, 2, 0, bias=False))\n",
    "        self.model.add_module('bnorm1',nn.BatchNorm2d(num_features*2))\n",
    "        self.model.add_module('relu1',nn.ReLU(True))\n",
    "        # 增加第二层反卷积层，输入2*num_features维，输出num_features维，窗口5，padding=0\n",
    "        # 输入图像大小为5，输出图像大小为W'=(W-1)S-2P+K+P'=(5-1)*2-2*0+5+0=13, 13*13\n",
    "        self.model.add_module('deconv2',nn.ConvTranspose2d(num_features*2, num_features, 5, 2, 0, bias=False))\n",
    "        self.model.add_module('bnorm2', nn.BatchNorm2d(num_features))\n",
    "        self.model.add_module('relu2',nn.ReLU(True))\n",
    "        # 增加第二层反卷积层，输入2*num_features维，输出num_features维，窗口4，padding=0\n",
    "        # 输入图像大小为13，输出图像大小为W'=(W-1)S-2P+K+P'=(13-1)*2-2*0+4+0=28, 28*28\n",
    "        self.model.add_module('deconv3',nn.ConvTranspose2d(num_features, num_channels, 4, 2, 0,bias=False))\n",
    "        self.model.add_module('sigmoid',nn.Sigmoid())\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        for name, module in self.model.named_children():\n",
    "            output = module(output)\n",
    "        return(output) # 28*28\n",
    "    \n",
    "    \n",
    "def weight_init(m):\n",
    "    #模型参数初始化．\n",
    "    #默认的初始化参数卷积核的权重是均值大概为0，方差在10^{-2}. BatchNorm层的权重均值是大约0.5，方差在0.2左右\n",
    "    #使用如下初始化方式可以，可以让方差更小，使得收敛更快\n",
    "    class_name=m.__class__.__name__\n",
    "    if class_name.find('conv')!=-1:\n",
    "        m.weight.data.normal_(0, 0.02)\n",
    "    if class_name.find('norm')!=-1:\n",
    "        m.weight.data.normal_(1.0,0.02)\n",
    "def make_show(img):\n",
    "    # 将张量变成可以显示的图像\n",
    "    img = img.data.expand(batch_size, 3, image_size, image_size)\n",
    "    return img\n",
    "def imshow(inp, title=None, ax=None):\n",
    "    # 在屏幕上绘制图像\n",
    "    if inp.size()[0] > 1:\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "    else:\n",
    "        inp = inp[0].numpy()\n",
    "    mvalue = np.amin(inp)\n",
    "    maxvalue = np.amax(inp)\n",
    "    if maxvalue > mvalue:\n",
    "        inp = (inp - mvalue)/(maxvalue - mvalue)\n",
    "    ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、生成器 － 识别器模型\n",
    "\n",
    "在这个模型中，我们不改变生成器，但是改变了网络的目标函数。我们加入了一个识别器，它通过固定值的方式迁移自一个手写体识别器\n",
    "然后让生成器生成图像，并让识别器进行识别，将识别的误差作为目标函数，调整生成器，从而能给出正确的分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义待迁移的网络框架，所有的神经网络模块包括：Conv2d、MaxPool2d，Linear等模块都不需要重新定义，会自动加载\n",
    "# 但是网络的forward功能没有办法自动实现，需要重写。\n",
    "# 一般的，加载网络只加载网络的属性，不加载方法\n",
    "depth = [4, 8]\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x\n",
    "    def retrieve_features(self, x):\n",
    "        feature_map1 = F.relu(self.conv1(x))\n",
    "        x = self.pool(feature_map1)\n",
    "        feature_map2 = F.relu(self.conv2(x))\n",
    "        return (feature_map1, feature_map2)\n",
    "    \n",
    "def rightness(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1]\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Z:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Z:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Z:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "netR = torch.load('minst_conv_checkpoint')\n",
    "netR = netR.cuda() if use_cuda else netR\n",
    "for para in netR.parameters():\n",
    "    para.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 源代码会遇到模型错误问题：Conv1d' object has no attribute 'padding_mode'   \n",
    "# 这是因为代码的pytorch版本是1.0 (https://blog.csdn.net/r1254/article/details/92813190)\n",
    "for m in netR.modules():\n",
    "    if 'Conv' in str(type(m)):\n",
    "        setattr(m, 'padding_mode', 'zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Z:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py:339: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练周期: 0 [6336/60000 (11%)]\t训练数据Loss: 2.638961,正确率: 21.48%\t校验数据Loss:1.514498,正确率:52.20%\n",
      "训练周期: 0 [12736/60000 (21%)]\t训练数据Loss: 2.071172,正确率: 33.30%\t校验数据Loss:0.944956,正确率:61.62%\n",
      "训练周期: 0 [19136/60000 (32%)]\t训练数据Loss: 1.785593,正确率: 41.28%\t校验数据Loss:0.836789,正确率:80.64%\n",
      "训练周期: 0 [25536/60000 (43%)]\t训练数据Loss: 1.609969,正确率: 46.34%\t校验数据Loss:0.605600,正确率:90.22%\n",
      "训练周期: 0 [31936/60000 (53%)]\t训练数据Loss: 1.473964,正确率: 50.27%\t校验数据Loss:0.528194,正确率:89.76%\n",
      "训练周期: 0 [38336/60000 (64%)]\t训练数据Loss: 1.381657,正确率: 52.94%\t校验数据Loss:0.558458,正确率:79.98%\n",
      "训练周期: 0 [44736/60000 (75%)]\t训练数据Loss: 1.299402,正确率: 55.72%\t校验数据Loss:0.434722,正确率:89.76%\n",
      "训练周期: 0 [51136/60000 (85%)]\t训练数据Loss: 1.226738,正确率: 58.01%\t校验数据Loss:0.425145,正确率:79.98%\n",
      "训练周期: 0 [57536/60000 (96%)]\t训练数据Loss: 1.165255,正确率: 59.97%\t校验数据Loss:0.301414,正确率:100.00%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "set_sizes_contiguous is not allowed on Tensor created from .data or .detach()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a04cf590eb9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# 产生一组图像保存到temp1文件夹下（需要事先建立好该文件夹），检测生成器当前的效果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: set_sizes_contiguous is not allowed on Tensor created from .data or .detach()"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "print('Initialized!')\n",
    "\n",
    "netG = ModelG()\n",
    "netG = netG.cuda() if use_cuda else netG\n",
    "netG.apply(weight_init) #初始化参数\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(netG.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "#随机选择batch_size个数字，用他们来生成数字图像\n",
    "samples = np.random.choice(10, batch_size)\n",
    "samples = torch.from_numpy(samples).type(dtype)\n",
    "\n",
    "num_epochs = 100\n",
    "step = 0\n",
    "statistics = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_rights = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target, data = data.clone().detach(), target.clone().detach()\n",
    "        if use_cuda:\n",
    "            target, data = target.cuda(), data.cuda()\n",
    "        # 复制标签变量放到了label中\n",
    "        label = data.clone()\n",
    "        data = data.type(dtype)\n",
    "        # 改变张量形状以适用于生成器网络\n",
    "        data = data.resize(data.size()[0], 1, 1, 1)\n",
    "        data = data.expand(data.size()[0], input_dim, 1, 1)\n",
    "        \n",
    "        netG.train()\n",
    "        netR.train() #这种区分主要是为了打开关闭net的training标志，从而决定是否运行dropout\n",
    "        output1 = netG(data)\n",
    "        output = netR(output1)\n",
    "        loss = criterion(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        if use_cuda:\n",
    "            loss = loss.cpu()\n",
    "        train_loss.append(loss.data.numpy())\n",
    "        right = rightness(output, label)\n",
    "        train_rights.append(right)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            netG.eval()\n",
    "            netR.eval()\n",
    "            val_loss = []\n",
    "            val_rights = []\n",
    "            \n",
    "            for (data, target) in validation_loader:\n",
    "                target, data = data.clone().detach(), target.clone().detach()\n",
    "                if use_cuda:\n",
    "                    target, data = target.cuda(), data.cuda()\n",
    "                label = data.clone()\n",
    "                data = data.type(dtype)\n",
    "                data = data.resize(data.size()[0], 1, 1, 1)\n",
    "                data = data.expand(data.size()[0], input_dim, 1, 1)\n",
    "                \n",
    "                output1 = netG(data) \n",
    "                output = netR(output1)\n",
    "                loss = criterion(output, label)\n",
    "                if use_cuda:\n",
    "                    loss = loss.cpu()\n",
    "                val_loss.append(loss.data.numpy())\n",
    "                right = rightness(output, label)\n",
    "                val_rights.append(right)\n",
    "                                  \n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "            print(('训练周期: {} [{}/{} ({:.0f}%)]\\t训练数据Loss: {:.6f},正确率: {:.2f}%\\t校验数据Loss:' +\n",
    "                  '{:.6f},正确率:{:.2f}%').format(epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), np.mean(train_loss), \n",
    "                                               100. * train_r[0].numpy() / train_r[1], \n",
    "                                               np.mean(val_loss), \n",
    "                                               100. * val_r[0].numpy() / val_r[1]))\n",
    "            statistics.append({'loss':np.mean(train_loss),'train': 100. * train_r[0] / train_r[1],\n",
    "                               'valid':100. * val_r[0] / val_r[1]})\n",
    "                                \n",
    "    # 产生一组图像保存到temp2文件夹下（需要事先建立好该文件夹），检测生成器当前的效果\n",
    "    samples.resize_(batch_size,1,1,1)\n",
    "    samples = samples.data.expand(batch_size, input_dim, 1, 1)\n",
    "    samples = samples.cuda() if use_cuda else samples\n",
    "    fake_u=netG(samples)\n",
    "    fake_u = fake_u.cpu() if use_cuda else fake_u\n",
    "    img = make_show(fake_u)\n",
    "    vutil.save_image(img,'temp2/fake%s.png'% (epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练曲线\n",
    "result1 = [100 - i['train'] for i in statistics]\n",
    "result2 = [100 - i['valid'] for i in statistics]\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot(result1, label = 'Training')\n",
    "plt.plot(result2, label = 'Validation')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#绘制一批样本\n",
    "samples = torch.Tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "samples = samples.type(dtype)\n",
    "\n",
    "sample_size = 10\n",
    "samples.data.resize_(sample_size,1,1,1)\n",
    "samples = samples.data.expand(sample_size, input_dim, 1, 1)\n",
    "samples = samples.cuda() if use_cuda else samples\n",
    "fake_u = netG(samples)\n",
    "fake_u = fake_u.cpu() if use_cuda else fake_u\n",
    "samples = samples.cpu() if use_cuda else samples\n",
    "img = fake_u\n",
    "f, axarr = plt.subplots(2,5, sharex=True, figsize=(15,6))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    axarr[i // 5, i % 5].axis('off')\n",
    "    imshow(img[i].data, samples.data.numpy()[i][0,0,0].astype(int), axarr[i // 5, i % 5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
